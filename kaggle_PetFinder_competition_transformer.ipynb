{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_PetFinder_competition_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNySRoQUK0a+tYCWGuee1yk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xedinseu/kaggle-competitions/blob/main/kaggle_PetFinder_competition_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ltvRvo_ubLO",
        "outputId": "c4f98dd4-837c-4f6b-ea5c-568daeed62bf"
      },
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 512 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 542 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 573 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 604 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 634 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 665 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 696 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 737 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 768 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 778 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 788 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 808 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 819 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 839 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 849 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 860 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 870 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 890 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 921 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 952 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 962 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 983 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 993 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.0 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol7-I7ILiDEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396f0f1d-b835-47d8-9a07-8eace7a0e705"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from PIL import Image # Модули работы с изображениями\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, concatenate, Dense, Dropout, BatchNormalization, Conv2D, Conv2DTranspose, MaxPooling2D, Flatten,Reshape, GlobalAveragePooling1D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW8PAELEiVAs",
        "outputId": "2c3312cf-fb9e-4a10-d9c3-b41b7cb39963"
      },
      "source": [
        "from google.colab import drive # подключаем гугл драйв диск для загрузки файлов\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqindGoT00vj"
      },
      "source": [
        "!unzip -q '/content/drive/MyDrive/Базы/petfinder-pawpularity-score.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JqU3xFyzBTV"
      },
      "source": [
        "# cat or dog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd9P-I220cB3"
      },
      "source": [
        "processed_path = '/content/petfinder-pawpularity-score/train/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBdUSPew6h-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd1ae04-eb88-4451-a0bd-4b9096bd88cb"
      },
      "source": [
        "df = pd.read_csv('/content/petfinder-pawpularity-score/train.csv')\n",
        "model_cod = ResNet50(weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 2s 0us/step\n",
            "102981632/102967424 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzbHnL334JZ0"
      },
      "source": [
        "def get_all_hyponyms(label):\n",
        "  syn = wn.synset(label)\n",
        "  return set([w.lower() for s in syn.closure(lambda s:s.hyponyms()) for w in s.lemma_names()])\n",
        "\n",
        "def cat_or_dog(predictions):\n",
        "  probs = np.array([e[2] for e in predictions])\n",
        "  \n",
        "  dog_arr = np.array([e[1].lower() in dogs for e in predictions])\n",
        "  dog = np.sum(dog_arr * probs)\n",
        "\n",
        "  cat_arr = np.array([e[1].lower() in cats for e in predictions])\n",
        "  cat = np.sum(cat_arr * probs)\n",
        "\n",
        "  neither_arr = np.logical_and(np.logical_not(dog_arr), np.logical_not(cat_arr))\n",
        "  neither = np.sum(neither_arr * probs)\n",
        "\n",
        "  res = \"neither\"\n",
        "  if dog > cat:\n",
        "    res = \"dog\"\n",
        "  elif dog < cat:\n",
        "    res = \"cat\"\n",
        "\n",
        "  return {'result':res, 'dog':dog, 'cat':cat, 'neither':neither}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lAHDx_24KUD"
      },
      "source": [
        "dogs = get_all_hyponyms(\"dog.n.01\")\n",
        "cats = get_all_hyponyms(\"cat.n.01\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttfBAIgJ4WhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c23617-0928-4f76-e146-a2e6363f5db7"
      },
      "source": [
        "import math\n",
        "\n",
        "labels = []\n",
        "batch_size = 500\n",
        "ids = list(df.Id)\n",
        "num_batches = math.ceil(len(ids) / batch_size)\n",
        "for batch in tqdm.tqdm(range(num_batches)):\n",
        "  images_batch = []\n",
        "  \n",
        "  for filename in ids[(batch_size*batch):(batch_size*batch+batch_size+1)]:\n",
        "    img_path = f'{processed_path}/{filename}.jpg'\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = image.smart_resize(img, (224, 224))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    images_batch.append(img)\n",
        "\n",
        "  preds = model_cod.predict_on_batch(np.array(images_batch).squeeze())\n",
        "  decoded = decode_predictions(preds, top=5)\n",
        "  batch_labels = [cat_or_dog(dec)['result'] for dec in decoded]\n",
        "  labels += batch_labels\n",
        "\n",
        "with open(f\"labels.csv\", \"w\") as fo:\n",
        "  for img_id, label in zip(ids, labels):\n",
        "    if label == 'dog':\n",
        "      label_num = 0\n",
        "    elif label == 'cat':\n",
        "      label_num = 1\n",
        "    else:\n",
        "      label_num = 2\n",
        "    fo.write(f\"{img_id},{label_num}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "49152/35363 [=========================================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [05:06<00:00, 15.32s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuWqUlnBzIyM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p07rhyLsiJlE"
      },
      "source": [
        "#data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1BMRuuviSmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5801308c-4ef6-4a74-f7a5-4c1ca1df7ce5"
      },
      "source": [
        "#####\n",
        "'''\n",
        "path = '/content/train/'\n",
        "processed_path = '/content/drive/MyDrive/Базы/temp/'\n",
        "'''\n",
        "#####"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\npath = '/content/train/'\\nprocessed_path = '/content/drive/MyDrive/Базы/temp/'\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL6pkwKajQ3h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4e6b256b-6a8a-4574-8ba7-2220791f1cb0"
      },
      "source": [
        "#####\n",
        "'''\n",
        "files = os.listdir(path) # Получаем список файлов\n",
        "k=0\n",
        "for f in files:\n",
        "  image = Image.open(path+f) # Загружаем изображение\n",
        "  iw, ih = image.size\n",
        "  w, h = (1280, 1280)\n",
        "  scale = min(w / iw, h / ih)\n",
        "  nw = int(iw * scale)\n",
        "  nh = int(ih * scale)\n",
        "  image_for_predict = image.resize((nw, nh), Image.BICUBIC)\n",
        "  new_image = Image.new('RGB', (1280,1280), (255,255,255))\n",
        "  new_image.paste(image_for_predict, ((w - nw) // 2, (h - nh) // 2))\n",
        "  new_image.save(processed_path+f)\n",
        "  k+=1\n",
        "'''\n",
        "####"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfiles = os.listdir(path) # Получаем список файлов\\nk=0\\nfor f in files:\\n  image = Image.open(path+f) # Загружаем изображение\\n  iw, ih = image.size\\n  w, h = (1280, 1280)\\n  scale = min(w / iw, h / ih)\\n  nw = int(iw * scale)\\n  nh = int(ih * scale)\\n  image_for_predict = image.resize((nw, nh), Image.BICUBIC)\\n  new_image = Image.new('RGB', (1280,1280), (255,255,255))\\n  new_image.paste(image_for_predict, ((w - nw) // 2, (h - nh) // 2))\\n  #new_image.convert('LA')\\n  new_image.save(processed_path+f)\\n  k+=1\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lal9lm8jbeS"
      },
      "source": [
        "x_train_label = pd.read_csv('/content/petfinder-pawpularity-score/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWp5Ebt36unP"
      },
      "source": [
        "x_train_cod = pd.read_csv('labels.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM2Avauz4EbQ"
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, batch_size=32, dim_1=(128,128),dim_2=(15),n_channels=3, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim_1 = dim_1\n",
        "        self.dim_2 = dim_2\n",
        "        self.batch_size = batch_size\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return [pic,lables], paw \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        pic = np.empty((self.batch_size, *self.dim_1, self.n_channels))\n",
        "        lables = np.empty((self.batch_size, self.dim_2))\n",
        "        paw = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
        "            label = x_train_label.loc[x_train_label['Id'] == ID].drop(['Id','Pawpularity'], axis=1).to_numpy()\n",
        "            cod = utils.to_categorical(x_train_cod.loc[x_train_cod[0] == ID].drop(0, axis=1),3)\n",
        "            lables[i,] = np.concatenate((label[0],cod[0]))\n",
        "            # Store class\n",
        "            paw[i] = x_train_label['Pawpularity'].loc[x_train_label['Id'] == ID]/100\n",
        "\n",
        "        return [pic,lables], paw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8XkD6G1o_g"
      },
      "source": [
        "# transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN9vh-SHCRsh"
      },
      "source": [
        "input_shape = (128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brfgvjYi1o_n"
      },
      "source": [
        "patch_size = (2, 2)  # 2-by-2 sized patches\n",
        "dropout_rate = 0.3  # Dropout rate\n",
        "num_heads = 8  # Attention heads\n",
        "embed_dim = 64  # Embedding dimension\n",
        "num_mlp = 256  # MLP layer size\n",
        "qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n",
        "window_size = 2  # Size of attention window\n",
        "shift_size = 1  # Size of shifting window\n",
        "image_dimension = 128  # Initial image size\n",
        "\n",
        "num_patch_x = input_shape[0] // patch_size[0]\n",
        "num_patch_y = input_shape[1] // patch_size[1]\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "validation_split = 0.1\n",
        "weight_decay = 0.0001\n",
        "label_smoothing = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_fp8YS1o_p"
      },
      "source": [
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
        "    )\n",
        "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        windows,\n",
        "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
        "    )\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "\n",
        "class DropPath(layers.Layer):\n",
        "    def __init__(self, drop_prob=None, **kwargs):\n",
        "        super(DropPath, self).__init__(**kwargs)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, x):\n",
        "        input_shape = tf.shape(x)\n",
        "        batch_size = input_shape[0]\n",
        "        rank = x.shape.rank\n",
        "        shape = (batch_size,) + (1,) * (rank - 1)\n",
        "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
        "        path_mask = tf.floor(random_tensor)\n",
        "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdK-y0yQ1o_p"
      },
      "source": [
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(\n",
        "        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n",
        "    ):\n",
        "        super(WindowAttention, self).__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (\n",
        "            2 * self.window_size[1] - 1\n",
        "        )\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=tf.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
        "        coords = np.stack(coords_matrix)\n",
        "        coords_flatten = coords.reshape(2, -1)\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = relative_coords.sum(-1)\n",
        "\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(\n",
        "            self.relative_position_index, shape=(-1,)\n",
        "        )\n",
        "        relative_position_bias = tf.gather(\n",
        "            self.relative_position_bias_table, relative_position_index_flat\n",
        "        )\n",
        "        relative_position_bias = tf.reshape(\n",
        "            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n",
        "        )\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.get_shape()[0]\n",
        "            mask_float = tf.cast(\n",
        "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
        "            )\n",
        "            attn = (\n",
        "                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
        "                + mask_float\n",
        "            )\n",
        "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d8hzYsQ1o_q"
      },
      "source": [
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        num_patch,\n",
        "        num_heads,\n",
        "        window_size=7,\n",
        "        shift_size=0,\n",
        "        num_mlp=1024,\n",
        "        qkv_bias=True,\n",
        "        dropout_rate=0.0,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super(SwinTransformer, self).__init__(**kwargs)\n",
        "\n",
        "        self.dim = dim  # number of input dimensions\n",
        "        self.num_patch = num_patch  # number of embedded patches\n",
        "        self.num_heads = num_heads  # number of attention heads\n",
        "        self.window_size = window_size  # size of window\n",
        "        self.shift_size = shift_size  # size of window shift\n",
        "        self.num_mlp = num_mlp  # number of MLP nodes\n",
        "\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = DropPath(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        self.mlp = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(num_mlp),\n",
        "                layers.Activation(keras.activations.gelu),\n",
        "                layers.Dropout(dropout_rate),\n",
        "                layers.Dense(dim),\n",
        "                layers.Dropout(dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            w_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "\n",
        "            # mask array to windows\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(\n",
        "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
        "            )\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
        "                mask_windows, axis=2\n",
        "            )\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, num_patches_before, channels = x.shape\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(\n",
        "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            shifted_x = x\n",
        "\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(\n",
        "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
        "        )\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "\n",
        "        attn_windows = tf.reshape(\n",
        "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
        "        )\n",
        "        shifted_x = window_reverse(\n",
        "            attn_windows, self.window_size, height, width, channels\n",
        "        )\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(\n",
        "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            x = shifted_x\n",
        "\n",
        "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
        "        x = self.drop_path(x)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x)\n",
        "        x = self.drop_path(x)\n",
        "        x = x_skip + x\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09g9-AuS1o_r"
      },
      "source": [
        "class PatchExtract(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super(PatchExtract, self).__init__(**kwargs)\n",
        "        self.patch_size_x = patch_size[0]\n",
        "        self.patch_size_y = patch_size[0]\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            rates=(1, 1, 1, 1),\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dim = patches.shape[-1]\n",
        "        patch_num = patches.shape[1]\n",
        "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super(PatchEmbedding, self).__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "\n",
        "class PatchMerging(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim):\n",
        "        super(PatchMerging, self).__init__()\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.get_shape().as_list()\n",
        "        x = tf.reshape(x, shape=(-1, height, width, C))\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
        "        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTsKoIYv1o_s"
      },
      "source": [
        "input = layers.Input(input_shape)\n",
        "x = layers.RandomCrop(image_dimension, image_dimension)(input)\n",
        "x = layers.RandomFlip(\"horizontal\")(x)\n",
        "x = PatchExtract(patch_size)(x)\n",
        "model_val = keras.Model(input,x)\n",
        "x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
        "x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=0,\n",
        "    num_mlp=num_mlp,\n",
        "    qkv_bias=qkv_bias,\n",
        "    dropout_rate=dropout_rate,\n",
        ")(x)\n",
        "x = SwinTransformer(\n",
        "    dim=embed_dim,\n",
        "    num_patch=(num_patch_x, num_patch_y),\n",
        "    num_heads=num_heads,\n",
        "    window_size=window_size,\n",
        "    shift_size=shift_size,\n",
        "    num_mlp=num_mlp,\n",
        "    qkv_bias=qkv_bias,\n",
        "    dropout_rate=dropout_rate,\n",
        ")(x)\n",
        "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "label_input = Input(15)\n",
        "label = Dense(64, activation='relu')(label_input)\n",
        "\n",
        "dense_conc = concatenate([x,label])\n",
        "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model([input,label_input], output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7mUsRf15Q5T"
      },
      "source": [
        "#FIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzNev4d7-7i0"
      },
      "source": [
        "params = {'dim_1': (128,128),\n",
        "          'dim_2': (15),\n",
        "          'batch_size': 64,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': True}\n",
        "partition = x_train_label['Id'].to_numpy()\n",
        "partition, partition_val = train_test_split(partition, test_size=0.1)\n",
        "training_generator = DataGenerator(partition, **params)\n",
        "validation_generator = DataGenerator(partition_val, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1j4gPoS15Es",
        "outputId": "026c4109-8e15-4941-8a26-7ec37cf3c3c6"
      },
      "source": [
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=Adam(learning_rate=1e-4, clipvalue=0.5),\n",
        ")\n",
        "model.fit(training_generator,validation_data=validation_generator, epochs=num_epochs, use_multiprocessing=True,workers=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "139/139 [==============================] - 261s 2s/step - loss: 0.0292 - val_loss: 0.0300\n",
            "Epoch 2/60\n",
            "139/139 [==============================] - 259s 2s/step - loss: 0.0287 - val_loss: 0.0296\n",
            "Epoch 3/60\n",
            "139/139 [==============================] - 257s 2s/step - loss: 0.0287 - val_loss: 0.0286\n",
            "Epoch 4/60\n",
            "139/139 [==============================] - 256s 2s/step - loss: 0.0284 - val_loss: 0.0286\n",
            "Epoch 5/60\n",
            "139/139 [==============================] - 257s 2s/step - loss: 0.0285 - val_loss: 0.0284\n",
            "Epoch 6/60\n",
            "139/139 [==============================] - 258s 2s/step - loss: 0.0286 - val_loss: 0.0293\n",
            "Epoch 7/60\n",
            "139/139 [==============================] - 255s 2s/step - loss: 0.0286 - val_loss: 0.0301\n",
            "Epoch 8/60\n",
            "139/139 [==============================] - 255s 2s/step - loss: 0.0286 - val_loss: 0.0356\n",
            "Epoch 9/60\n",
            "139/139 [==============================] - 258s 2s/step - loss: 0.0284 - val_loss: 0.0307\n",
            "Epoch 10/60\n",
            "139/139 [==============================] - 259s 2s/step - loss: 0.0281 - val_loss: 0.0332\n",
            "Epoch 11/60\n",
            "139/139 [==============================] - 257s 2s/step - loss: 0.0284 - val_loss: 0.0412\n",
            "Epoch 12/60\n",
            "139/139 [==============================] - 256s 2s/step - loss: 0.0285 - val_loss: 0.0277\n",
            "Epoch 13/60\n",
            "139/139 [==============================] - 256s 2s/step - loss: 0.0283 - val_loss: 0.0378\n",
            "Epoch 14/60\n",
            "139/139 [==============================] - 257s 2s/step - loss: 0.0284 - val_loss: 0.0371\n",
            "Epoch 15/60\n",
            "139/139 [==============================] - 257s 2s/step - loss: 0.0284 - val_loss: 0.0302\n",
            "Epoch 16/60\n",
            "139/139 [==============================] - 258s 2s/step - loss: 0.0285 - val_loss: 0.0338\n",
            "Epoch 17/60\n",
            "139/139 [==============================] - 256s 2s/step - loss: 0.0283 - val_loss: 0.0373\n",
            "Epoch 18/60\n",
            "139/139 [==============================] - 256s 2s/step - loss: 0.0284 - val_loss: 0.0319\n",
            "Epoch 19/60\n",
            "139/139 [==============================] - 265s 2s/step - loss: 0.0284 - val_loss: 0.0274\n",
            "Epoch 20/60\n",
            "139/139 [==============================] - 259s 2s/step - loss: 0.0283 - val_loss: 0.0330\n",
            "Epoch 21/60\n",
            "139/139 [==============================] - 259s 2s/step - loss: 0.0282 - val_loss: 0.0319\n",
            "Epoch 22/60\n",
            "139/139 [==============================] - 268s 2s/step - loss: 0.0283 - val_loss: 0.0356\n",
            "Epoch 23/60\n",
            "139/139 [==============================] - 273s 2s/step - loss: 0.0283 - val_loss: 0.0402\n",
            "Epoch 24/60\n",
            "139/139 [==============================] - 258s 2s/step - loss: 0.0282 - val_loss: 0.0373\n",
            "Epoch 25/60\n",
            "139/139 [==============================] - ETA: 0s - loss: 0.0283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Keras_worker_ForkPoolWorker-594:\n",
            "Process Keras_worker_ForkPoolWorker-586:\n",
            "Process Keras_worker_ForkPoolWorker-585:\n",
            "Process Keras_worker_ForkPoolWorker-584:\n",
            "Process Keras_worker_ForkPoolWorker-587:\n",
            "Process Keras_worker_ForkPoolWorker-583:\n",
            "Process Keras_worker_ForkPoolWorker-588:\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-589:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-591:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "Process Keras_worker_ForkPoolWorker-593:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "Process Keras_worker_ForkPoolWorker-590:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "Traceback (most recent call last):\n",
            "Process Keras_worker_ForkPoolWorker-592:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 51, in __data_generation\n",
            "    paw[i] = x_train_label['Pawpularity'].loc[x_train_label['Id'] == ID]/100\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\", line 879, in __getitem__\n",
            "    return self._getitem_axis(maybe_callable, axis=axis)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\", line 1090, in _getitem_axis\n",
            "    return self._getbool_axis(key, axis=axis)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\", line 896, in _getbool_axis\n",
            "    key = check_bool_indexer(labels, key)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\", line 2191, in check_bool_indexer\n",
            "    elif not is_array_like(result):\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 207, in load\n",
            "    self.load_prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/inference.py\", line 214, in is_array_like\n",
            "    return is_list_like(obj) and hasattr(obj, \"dtype\")\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "KeyboardInterrupt\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "  File \"pandas/_libs/lib.pyx\", line 1005, in pandas._libs.lib.is_list_like\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 277, in load_prepare\n",
            "    self.im = Image.core.new(self.mode, self.size)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 563, in get_index\n",
            "    return _SHARED_SEQUENCES[uid][i]\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"pandas/_libs/lib.pyx\", line 1010, in pandas._libs.lib.c_is_list_like\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 26, in __getitem__\n",
            "    [pic,lables], paw = self.__data_generation(list_IDs_temp)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"<ipython-input-25-f01f4cd8c513>\", line 46, in __data_generation\n",
            "    pic[i,] = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "  File \"/usr/lib/python3.7/abc.py\", line 139, in __instancecheck__\n",
            "    return _abc_instancecheck(cls, instance)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\", line 314, in load_img\n",
            "    target_size=target_size, interpolation=interpolation)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n",
            "    img = img.resize(width_height_tuple, resample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n",
            "    self.load()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 251, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFAMHzhaEoMs"
      },
      "source": [
        "#Class = model_class.predict([x_test_pic,x_test_label])\n",
        "Paw = model.predict([x_val_pic,x_val_label,pred_class])\n",
        "PawPularity = []\n",
        "for i in range(Paw.shape[0]):\n",
        "    PawPularity.append(Paw[i][0])\n",
        "submission = pd.DataFrame(columns=['Real_Pawpularity','Pawpularity'])\n",
        "submission['Pawpularity'] = np.array(PawPularity)*100\n",
        "submission['Real_Pawpularity'] = np.array(y_val)*100\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "jQ-U4WwWWtMF",
        "outputId": "296c56d4-b344-488e-b295-ae9358e74c9d"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Real_Pawpularity</th>\n",
              "      <th>Pawpularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>44.040043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32.0</td>\n",
              "      <td>37.537731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.614750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76.0</td>\n",
              "      <td>49.183361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26.0</td>\n",
              "      <td>35.223343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>57.0</td>\n",
              "      <td>34.869213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>31.0</td>\n",
              "      <td>41.066990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>39.0</td>\n",
              "      <td>34.740875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961</th>\n",
              "      <td>53.0</td>\n",
              "      <td>50.100868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>26.0</td>\n",
              "      <td>48.222519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>963 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Real_Pawpularity  Pawpularity\n",
              "0                22.0    44.040043\n",
              "1                32.0    37.537731\n",
              "2                35.0    40.614750\n",
              "3                76.0    49.183361\n",
              "4                26.0    35.223343\n",
              "..                ...          ...\n",
              "958              57.0    34.869213\n",
              "959              31.0    41.066990\n",
              "960              39.0    34.740875\n",
              "961              53.0    50.100868\n",
              "962              26.0    48.222519\n",
              "\n",
              "[963 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkDAx5boU337"
      },
      "source": [
        "model.save('/content/drive/MyDrive/data/kaggle2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}