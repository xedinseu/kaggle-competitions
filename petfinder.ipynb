{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom PIL import Image # Модули работы с изображениями\nfrom tensorflow.keras.preprocessing import image\nimport os\nimport matplotlib.pyplot as plt\nimport copy\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, concatenate, Dense, Dropout, BatchNormalization, Conv2D, Conv2DTranspose, MaxPooling2D, Flatten,Reshape, GlobalAveragePooling1D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.callbacks import LambdaCallback\nimport tensorflow as tf\n\nimport tensorflow_addons as tfa\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom learntools.deep_learning.decode_predictions import decode_predictions\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom nltk.corpus import wordnet as wn\nimport nltk\n#nltk.download(\"wordnet\")\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:34:39.281365Z","iopub.execute_input":"2021-10-18T08:34:39.281733Z","iopub.status.idle":"2021-10-18T08:34:39.292999Z","shell.execute_reply.started":"2021-10-18T08:34:39.281692Z","shell.execute_reply":"2021-10-18T08:34:39.292343Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"processed_path = '../input/petfinder-pawpularity-score/train/'\ndf = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\nmodel_cod = keras.models.load_model('../input/cat-or-dog-model/cat_or_dog_model.h5')\ndef get_all_hyponyms(label):\n  syn = wn.synset(label)\n  return set([w.lower() for s in syn.closure(lambda s:s.hyponyms()) for w in s.lemma_names()])\n\ndef cat_or_dog(predictions):\n  probs = np.array([e[2] for e in predictions])\n  \n  dog_arr = np.array([e[1].lower() in dogs for e in predictions])\n  dog = np.sum(dog_arr * probs)\n\n  cat_arr = np.array([e[1].lower() in cats for e in predictions])\n  cat = np.sum(cat_arr * probs)\n\n  neither_arr = np.logical_and(np.logical_not(dog_arr), np.logical_not(cat_arr))\n  neither = np.sum(neither_arr * probs)\n\n  res = \"neither\"\n  if dog > cat:\n    res = \"dog\"\n  elif dog < cat:\n    res = \"cat\"\n\n  return {'result':res, 'dog':dog, 'cat':cat, 'neither':neither}\ndogs = get_all_hyponyms(\"dog.n.01\")\ncats = get_all_hyponyms(\"cat.n.01\")\nimport math\n\nlabels = []\nbatch_size = 500\nids = list(df.Id)\nnum_batches = math.ceil(len(ids) / batch_size)\n\nfor batch in tqdm.tqdm(range(num_batches)):\n  images_batch = []\n  \n  for filename in ids[(batch_size*batch):(batch_size*batch+batch_size+1)]:\n    img_path = f'{processed_path}/{filename}.jpg'\n    img = image.load_img(img_path, target_size=(224, 224))\n    img = image.img_to_array(img)\n    img = image.smart_resize(img, (224, 224))\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n    images_batch.append(img)\n#######################################\n  preds = model_cod.predict_on_batch(np.array(images_batch).squeeze())\n  decoded = decode_predictions(preds, top=5, class_list_path='../input/keras-pretrained-models/imagenet_class_index.json')\n  batch_labels = [cat_or_dog(dec)['result'] for dec in decoded]\n  labels += batch_labels\n#######################################\nwith open(f\"labels.csv\", \"w\") as fo:\n  for img_id, label in zip(ids, labels):\n    if label == 'dog':\n      label_num = 0\n    elif label == 'cat':\n      label_num = 1\n    else:\n      label_num = 2\n    fo.write(f\"{img_id},{label_num}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:34:39.294750Z","iopub.execute_input":"2021-10-18T08:34:39.295242Z","iopub.status.idle":"2021-10-18T08:37:26.640508Z","shell.execute_reply.started":"2021-10-18T08:34:39.295198Z","shell.execute_reply":"2021-10-18T08:37:26.639216Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"processed_path = '../input/petfinder-pawpularity-score/train/'\nx_train_label = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\nx_train_cod = pd.read_csv('labels.csv',header=None)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:42:30.236569Z","iopub.execute_input":"2021-10-18T08:42:30.237231Z","iopub.status.idle":"2021-10-18T08:42:30.266299Z","shell.execute_reply.started":"2021-10-18T08:42:30.237193Z","shell.execute_reply":"2021-10-18T08:42:30.265586Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, batch_size=32, dim_1=(128,128),dim_2=(15),n_channels=3, shuffle=True):\n        'Initialization'\n        self.dim_1 = dim_1\n        self.dim_2 = dim_2\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        [pic,lables], paw = self.__data_generation(list_IDs_temp)\n\n        return [pic,lables], paw \n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        pic = []\n        lables = []\n        paw = []\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            pic.append(np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(self.dim_1[0], self.dim_1[1]))))/255) \n            label = x_train_label.loc[x_train_label['Id'] == ID].drop(['Id','Pawpularity'], axis=1).to_numpy()\n            cod = utils.to_categorical(x_train_cod.loc[x_train_cod[0] == ID].drop(0, axis=1),3)\n            lables.append(np.concatenate((label[0],cod[0]))) \n            # Store class\n            paw.append(np.array(x_train_label['Pawpularity'].loc[x_train_label['Id'] == ID])[0]/100)\n\n        return [np.array(pic),np.array(lables)], np.array(paw)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:37:26.670989Z","iopub.execute_input":"2021-10-18T08:37:26.671253Z","iopub.status.idle":"2021-10-18T08:37:26.686890Z","shell.execute_reply.started":"2021-10-18T08:37:26.671219Z","shell.execute_reply":"2021-10-18T08:37:26.685799Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"input_shape = (256, 256, 3)\npatch_size = (2, 2)  # 2-by-2 sized patches\ndropout_rate = 0.2  # Dropout rate\nnum_heads = 8  # Attention heads\nembed_dim = 64  # Embedding dimension\nnum_mlp = 256  # MLP layer size\nqkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\nwindow_size = 2  # Size of attention window\nshift_size = 1  # Size of shifting window\nimage_dimension = 256  # Initial image size\n\nnum_patch_x = input_shape[0] // patch_size[0]\nnum_patch_y = input_shape[1] // patch_size[1]\n\nlearning_rate = 1e-3\nbatch_size = 64\nnum_epochs = 20\nvalidation_split = 0.1\nweight_decay = 0.0001\nlabel_smoothing = 0.1\ndef window_partition(x, window_size):\n    _, height, width, channels = x.shape\n    patch_num_y = height // window_size\n    patch_num_x = width // window_size\n    x = tf.reshape(\n        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n    )\n    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n    return windows\n\n\ndef window_reverse(windows, window_size, height, width, channels):\n    patch_num_y = height // window_size\n    patch_num_x = width // window_size\n    x = tf.reshape(\n        windows,\n        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n    )\n    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n    x = tf.reshape(x, shape=(-1, height, width, channels))\n    return x\n\n\nclass DropPath(layers.Layer):\n    def __init__(self, drop_prob=None, **kwargs):\n        super(DropPath, self).__init__(**kwargs)\n        self.drop_prob = drop_prob\n\n    def call(self, x):\n        input_shape = tf.shape(x)\n        batch_size = input_shape[0]\n        rank = x.shape.rank\n        shape = (batch_size,) + (1,) * (rank - 1)\n        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n        path_mask = tf.floor(random_tensor)\n        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n        return output\nclass WindowAttention(layers.Layer):\n    def __init__(\n        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n    ):\n        super(WindowAttention, self).__init__(**kwargs)\n        self.dim = dim\n        self.window_size = window_size\n        self.num_heads = num_heads\n        self.scale = (dim // num_heads) ** -0.5\n        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n        self.dropout = layers.Dropout(dropout_rate)\n        self.proj = layers.Dense(dim)\n\n    def build(self, input_shape):\n        num_window_elements = (2 * self.window_size[0] - 1) * (\n            2 * self.window_size[1] - 1\n        )\n        self.relative_position_bias_table = self.add_weight(\n            shape=(num_window_elements, self.num_heads),\n            initializer=tf.initializers.Zeros(),\n            trainable=True,\n        )\n        coords_h = np.arange(self.window_size[0])\n        coords_w = np.arange(self.window_size[1])\n        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n        coords = np.stack(coords_matrix)\n        coords_flatten = coords.reshape(2, -1)\n        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n        relative_coords = relative_coords.transpose([1, 2, 0])\n        relative_coords[:, :, 0] += self.window_size[0] - 1\n        relative_coords[:, :, 1] += self.window_size[1] - 1\n        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n        relative_position_index = relative_coords.sum(-1)\n\n        self.relative_position_index = tf.Variable(\n            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n        )\n\n    def call(self, x, mask=None):\n        _, size, channels = x.shape\n        head_dim = channels // self.num_heads\n        x_qkv = self.qkv(x)\n        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n        q = q * self.scale\n        k = tf.transpose(k, perm=(0, 1, 3, 2))\n        attn = q @ k\n\n        num_window_elements = self.window_size[0] * self.window_size[1]\n        relative_position_index_flat = tf.reshape(\n            self.relative_position_index, shape=(-1,)\n        )\n        relative_position_bias = tf.gather(\n            self.relative_position_bias_table, relative_position_index_flat\n        )\n        relative_position_bias = tf.reshape(\n            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n        )\n        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n\n        if mask is not None:\n            nW = mask.get_shape()[0]\n            mask_float = tf.cast(\n                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n            )\n            attn = (\n                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n                + mask_float\n            )\n            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n            attn = keras.activations.softmax(attn, axis=-1)\n        else:\n            attn = keras.activations.softmax(attn, axis=-1)\n        attn = self.dropout(attn)\n\n        x_qkv = attn @ v\n        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n        x_qkv = self.proj(x_qkv)\n        x_qkv = self.dropout(x_qkv)\n        return x_qkv\nclass SwinTransformer(layers.Layer):\n    def __init__(\n        self,\n        dim,\n        num_patch,\n        num_heads,\n        window_size=7,\n        shift_size=0,\n        num_mlp=1024,\n        qkv_bias=True,\n        dropout_rate=0.0,\n        **kwargs,\n    ):\n        super(SwinTransformer, self).__init__(**kwargs)\n\n        self.dim = dim  # number of input dimensions\n        self.num_patch = num_patch  # number of embedded patches\n        self.num_heads = num_heads  # number of attention heads\n        self.window_size = window_size  # size of window\n        self.shift_size = shift_size  # size of window shift\n        self.num_mlp = num_mlp  # number of MLP nodes\n\n        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n        self.attn = WindowAttention(\n            dim,\n            window_size=(self.window_size, self.window_size),\n            num_heads=num_heads,\n            qkv_bias=qkv_bias,\n            dropout_rate=dropout_rate,\n        )\n        self.drop_path = DropPath(dropout_rate)\n        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n\n        self.mlp = keras.Sequential(\n            [\n                layers.Dense(num_mlp),\n                layers.Activation(keras.activations.gelu),\n                layers.Dropout(dropout_rate),\n                layers.Dense(dim),\n                layers.Dropout(dropout_rate),\n            ]\n        )\n\n        if min(self.num_patch) < self.window_size:\n            self.shift_size = 0\n            self.window_size = min(self.num_patch)\n\n    def build(self, input_shape):\n        if self.shift_size == 0:\n            self.attn_mask = None\n        else:\n            height, width = self.num_patch\n            h_slices = (\n                slice(0, -self.window_size),\n                slice(-self.window_size, -self.shift_size),\n                slice(-self.shift_size, None),\n            )\n            w_slices = (\n                slice(0, -self.window_size),\n                slice(-self.window_size, -self.shift_size),\n                slice(-self.shift_size, None),\n            )\n            mask_array = np.zeros((1, height, width, 1))\n            count = 0\n            for h in h_slices:\n                for w in w_slices:\n                    mask_array[:, h, w, :] = count\n                    count += 1\n            mask_array = tf.convert_to_tensor(mask_array)\n\n            # mask array to windows\n            mask_windows = window_partition(mask_array, self.window_size)\n            mask_windows = tf.reshape(\n                mask_windows, shape=[-1, self.window_size * self.window_size]\n            )\n            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n                mask_windows, axis=2\n            )\n            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n\n    def call(self, x):\n        height, width = self.num_patch\n        _, num_patches_before, channels = x.shape\n        x_skip = x\n        x = self.norm1(x)\n        x = tf.reshape(x, shape=(-1, height, width, channels))\n        if self.shift_size > 0:\n            shifted_x = tf.roll(\n                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n            )\n        else:\n            shifted_x = x\n\n        x_windows = window_partition(shifted_x, self.window_size)\n        x_windows = tf.reshape(\n            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n        )\n        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n\n        attn_windows = tf.reshape(\n            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n        )\n        shifted_x = window_reverse(\n            attn_windows, self.window_size, height, width, channels\n        )\n        if self.shift_size > 0:\n            x = tf.roll(\n                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n            )\n        else:\n            x = shifted_x\n\n        x = tf.reshape(x, shape=(-1, height * width, channels))\n        x = self.drop_path(x)\n        x = x_skip + x\n        x_skip = x\n        x = self.norm2(x)\n        x = self.mlp(x)\n        x = self.drop_path(x)\n        x = x_skip + x\n        return x\nclass PatchExtract(layers.Layer):\n    def __init__(self, patch_size, **kwargs):\n        super(PatchExtract, self).__init__(**kwargs)\n        self.patch_size_x = patch_size[0]\n        self.patch_size_y = patch_size[0]\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n            rates=(1, 1, 1, 1),\n            padding=\"VALID\",\n        )\n        patch_dim = patches.shape[-1]\n        patch_num = patches.shape[1]\n        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n\n\nclass PatchEmbedding(layers.Layer):\n    def __init__(self, num_patch, embed_dim, **kwargs):\n        super(PatchEmbedding, self).__init__(**kwargs)\n        self.num_patch = num_patch\n        self.proj = layers.Dense(embed_dim)\n        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n\n    def call(self, patch):\n        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n        return self.proj(patch) + self.pos_embed(pos)\n\n\nclass PatchMerging(tf.keras.layers.Layer):\n    def __init__(self, num_patch, embed_dim):\n        super(PatchMerging, self).__init__()\n        self.num_patch = num_patch\n        self.embed_dim = embed_dim\n        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n\n    def call(self, x):\n        height, width = self.num_patch\n        _, _, C = x.get_shape().as_list()\n        x = tf.reshape(x, shape=(-1, height, width, C))\n        x0 = x[:, 0::2, 0::2, :]\n        x1 = x[:, 1::2, 0::2, :]\n        x2 = x[:, 0::2, 1::2, :]\n        x3 = x[:, 1::2, 1::2, :]\n        x = tf.concat((x0, x1, x2, x3), axis=-1)\n        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n        return self.linear_trans(x)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:42:36.887259Z","iopub.execute_input":"2021-10-18T08:42:36.887631Z","iopub.status.idle":"2021-10-18T08:42:36.949106Z","shell.execute_reply.started":"2021-10-18T08:42:36.887566Z","shell.execute_reply":"2021-10-18T08:42:36.948257Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"pic_input = layers.Input(input_shape)\nx = layers.experimental.preprocessing.RandomCrop(image_dimension, image_dimension)(pic_input)\nx = layers.experimental.preprocessing.RandomFlip(\"horizontal\")(x)\nx = PatchExtract(patch_size)(x)\nmodel_val = keras.Model(pic_input,x)\nx = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\nx = SwinTransformer(\n    dim=embed_dim,\n    num_patch=(num_patch_x, num_patch_y),\n    num_heads=num_heads,\n    window_size=window_size,\n    shift_size=0,\n    num_mlp=num_mlp,\n    qkv_bias=qkv_bias,\n    dropout_rate=dropout_rate,\n)(x)\nx = SwinTransformer(\n    dim=embed_dim,\n    num_patch=(num_patch_x, num_patch_y),\n    num_heads=num_heads,\n    window_size=window_size,\n    shift_size=shift_size,\n    num_mlp=num_mlp,\n    qkv_bias=qkv_bias,\n    dropout_rate=dropout_rate,\n)(x)\nx = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\nx = layers.GlobalAveragePooling1D()(x)\n\nlabel_input = Input(15)\nlabel = Dense(64, activation='relu')(label_input)\n\ndense_conc = concatenate([x,label])\noutput = layers.Dense(1, activation=\"sigmoid\")(x)\nmodel = keras.Model([pic_input,label_input], output)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:42:43.320336Z","iopub.execute_input":"2021-10-18T08:42:43.320624Z","iopub.status.idle":"2021-10-18T08:42:43.847248Z","shell.execute_reply.started":"2021-10-18T08:42:43.320567Z","shell.execute_reply":"2021-10-18T08:42:43.846520Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"params = {'dim_1': (256,256),\n          'dim_2': (15),\n          'batch_size': 32,\n          'n_channels': 3,\n          'shuffle': True}\npartition = x_train_label['Id'].to_numpy()\npartition, partition_val = train_test_split(partition, test_size=0.1)\ntraining_generator = DataGenerator(partition, **params)\nvalidation_generator = DataGenerator(partition_val, **params)\nmodel.compile(\n    loss='mse',\n    optimizer=Adam(learning_rate=1e-4, clipvalue=0.5),\n)\nmodel.fit(training_generator,validation_data=validation_generator, epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:42:46.407560Z","iopub.execute_input":"2021-10-18T08:42:46.408015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_path = '../input/petfinder-pawpularity-score/test/'\ndf = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\nmodel_cod = keras.models.load_model('../input/cat-or-dog-model/cat_or_dog_model.h5')\ndef get_all_hyponyms(label):\n  syn = wn.synset(label)\n  return set([w.lower() for s in syn.closure(lambda s:s.hyponyms()) for w in s.lemma_names()])\n\ndef cat_or_dog(predictions):\n  probs = np.array([e[2] for e in predictions])\n  \n  dog_arr = np.array([e[1].lower() in dogs for e in predictions])\n  dog = np.sum(dog_arr * probs)\n\n  cat_arr = np.array([e[1].lower() in cats for e in predictions])\n  cat = np.sum(cat_arr * probs)\n\n  neither_arr = np.logical_and(np.logical_not(dog_arr), np.logical_not(cat_arr))\n  neither = np.sum(neither_arr * probs)\n\n  res = \"neither\"\n  if dog > cat:\n    res = \"dog\"\n  elif dog < cat:\n    res = \"cat\"\n\n  return {'result':res, 'dog':dog, 'cat':cat, 'neither':neither}\ndogs = get_all_hyponyms(\"dog.n.01\")\ncats = get_all_hyponyms(\"cat.n.01\")\nimport math\n\nlabels = []\nbatch_size = 500\nids = list(df.Id)\nnum_batches = math.ceil(len(ids) / batch_size)\nfor batch in tqdm.tqdm(range(num_batches)):\n  images_batch = []\n  \n  for filename in ids[(batch_size*batch):(batch_size*batch+batch_size+1)]:\n    img_path = f'{processed_path}/{filename}.jpg'\n    img = image.load_img(img_path, target_size=(224, 224))\n    img = image.img_to_array(img)\n    img = image.smart_resize(img, (224, 224))\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n    images_batch.append(img)\n\n  preds = model_cod.predict_on_batch(np.array(images_batch).squeeze())\n  decoded = decode_predictions(preds, top=5, class_list_path='../input/keras-pretrained-models/imagenet_class_index.json')\n  batch_labels = [cat_or_dog(dec)['result'] for dec in decoded]\n  labels += batch_labels\n\nwith open(f\"labels_test.csv\", \"w\") as fo:\n  for img_id, label in zip(ids, labels):\n    if label == 'dog':\n      label_num = 0\n    elif label == 'cat':\n      label_num = 1\n    else:\n      label_num = 2\n    fo.write(f\"{img_id},{label_num}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:41:13.119851Z","iopub.execute_input":"2021-10-18T08:41:13.121970Z","iopub.status.idle":"2021-10-18T08:41:17.779569Z","shell.execute_reply.started":"2021-10-18T08:41:13.121932Z","shell.execute_reply":"2021-10-18T08:41:17.778670Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"processed_path = '../input/petfinder-pawpularity-score/test/'\nx_test_label = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\nx_test_cod = pd.read_csv('labels_test.csv', header=None)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:41:17.780723Z","iopub.execute_input":"2021-10-18T08:41:17.781458Z","iopub.status.idle":"2021-10-18T08:41:17.792193Z","shell.execute_reply.started":"2021-10-18T08:41:17.781417Z","shell.execute_reply":"2021-10-18T08:41:17.791390Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"PawPularity = []\nIDs = []\nfor ID in x_test_label['Id'].to_numpy():\n    pic_test = np.array(image.img_to_array(image.load_img(os.path.join(processed_path, ID + '.jpg'), target_size=(256, 256))))/255\n    label_test = x_test_label.loc[x_test_label['Id'] == ID].drop(['Id'], axis=1).to_numpy()\n    cod_test = utils.to_categorical(x_test_cod.loc[x_test_cod[0] == ID].drop(0, axis=1),3)\n    lables_test = np.concatenate((label_test[0],cod_test[0]))\n    pic_test = np.expand_dims(pic_test, axis=0)\n    lables_test = np.expand_dims(lables_test, axis=0)\n    PawPularity.append(model.predict([pic_test,lables_test])[0][0])\n    IDs.append(ID)\nsubmission = pd.DataFrame(columns=['Id','Pawpularity'])\nsubmission['Pawpularity'] = np.array(PawPularity)*100\nsubmission['Id'] = np.array(IDs)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:41:17.795940Z","iopub.execute_input":"2021-10-18T08:41:17.796270Z","iopub.status.idle":"2021-10-18T08:41:18.735725Z","shell.execute_reply.started":"2021-10-18T08:41:17.796246Z","shell.execute_reply":"2021-10-18T08:41:18.734997Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-10-18T08:41:18.736910Z","iopub.execute_input":"2021-10-18T08:41:18.737176Z","iopub.status.idle":"2021-10-18T08:41:18.753176Z","shell.execute_reply.started":"2021-10-18T08:41:18.737142Z","shell.execute_reply":"2021-10-18T08:41:18.752513Z"},"trusted":true},"execution_count":32,"outputs":[]}]}